{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Synthesis: MNIST to Object Detection\n",
    "\n",
    "Let's synthesize a dataset from MINST since digits are usually not standalone in the real world.\n",
    "\n",
    "- Input: Images of digits\n",
    "- Output: An image of scattered digits with bounding boxes (`label`, `x_rel`, `y_rel`, `w_rel`, `h_rel`) for each digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 09:56:22.118385: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-23 09:56:22.118867: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-23 09:56:22.121782: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-23 09:56:22.161900: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-23 09:56:22.816159: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/hgoz/miniconda3/envs/t5/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('generated/mnist-detection/images', exist_ok=True)\n",
    "os.makedirs('generated/mnist-detection/labels', exist_ok=True)\n",
    "\n",
    "def save_example(filename, image, label_rows=[]):\n",
    "    \"\"\"Save an image and its label to disk.\n",
    "    \n",
    "    Args:\n",
    "        filename: (string) - the filename to save the image and label to\n",
    "        image: (np.ndarray) - the image to save\n",
    "        label_rows: (tuple[label, x_rel, y_rel, w_rel, h_rel]) the list of label rows to save\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # save image file\n",
    "    img = Image.fromarray(image.squeeze(), mode='L')\n",
    "    with open(os.path.join('generated', 'mnist-detection', 'images', f'{filename}.png'), 'wb') as f:\n",
    "        img.save(f)\n",
    "    \n",
    "    # save label file\n",
    "    with open(os.path.join('generated', 'mnist-detection', 'labels', f'{filename}.txt'), 'w') as f:\n",
    "        for row in label_rows:\n",
    "            label, x_rel, y_rel, w_rel, h_rel = row\n",
    "            txt_rows = f'{label}\\t{x_rel}\\t{y_rel}\\t{w_rel}\\t{h_rel}\\n'\n",
    "            f.write(txt_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_NUM_OBJECTS = 5\n",
    "\n",
    "OBJ_HEIGHT = 28\n",
    "OBJ_WIDTH = 28\n",
    " \n",
    "IMG_HEIGHT = OBJ_HEIGHT * 8\n",
    "IMG_WIDTH = OBJ_WIDTH * 8\n",
    "\n",
    "MARGIN_Y = OBJ_HEIGHT\n",
    "MARGIN_X = OBJ_WIDTH\n",
    "\n",
    "NUM_EXAMPLES = 10\n",
    "\n",
    "BATCH_SIZE = MIN_NUM_OBJECTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds, info = tfds.load('mnist', split='train', shuffle_files=True, as_supervised=True, with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 09:56:24.171364: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-04-23 09:56:24.198183: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-04-23 09:56:24.252387: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-04-23 09:56:24.253418: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-04-23 09:56:24.302651: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-04-23 09:56:24.305336: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-04-23 09:56:24.358884: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-04-23 09:56:24.361288: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-04-23 09:56:24.416681: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-04-23 09:56:24.420239: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-04-23 09:56:24.474423: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-04-23 09:56:24.477585: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-04-23 09:56:24.529514: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-04-23 09:56:24.533249: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-04-23 09:56:24.587032: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-04-23 09:56:24.591521: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-04-23 09:56:24.644133: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-04-23 09:56:24.647730: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-04-23 09:56:24.697995: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-04-23 09:56:24.700793: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "batches = ds.batch(BATCH_SIZE)\n",
    "\n",
    "for i in range(NUM_EXAMPLES):\n",
    "    image = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.uint8)\n",
    "    label_rows = []\n",
    "    for features, labels in batches.skip(i*BATCH_SIZE).take(1):\n",
    "        for j in range(features.shape[0]):\n",
    "            # pick a random position, subject to margin constraints\n",
    "            y_pos = int(max(MARGIN_Y, min(random.random() * IMG_HEIGHT, IMG_HEIGHT - MARGIN_Y*2)))\n",
    "            x_pos = int(max(MARGIN_X, min(random.random() * IMG_WIDTH, IMG_WIDTH - MARGIN_X*2)))\n",
    "            \n",
    "            # paste the pixels at that position, using bit-wise OR to allow for overlapping objects\n",
    "            image[y_pos:y_pos+OBJ_HEIGHT, x_pos:x_pos+OBJ_WIDTH] = image[y_pos:y_pos+OBJ_HEIGHT, x_pos:x_pos+OBJ_WIDTH] | features[j]\n",
    "            \n",
    "            # DEBUG: show the image\n",
    "            # plt.imshow(image, cmap='gray')\n",
    "            # plt.show()\n",
    "            \n",
    "            y_rel = y_pos / IMG_HEIGHT\n",
    "            x_rel = x_pos / IMG_WIDTH\n",
    "            w_rel = OBJ_WIDTH / IMG_WIDTH\n",
    "            h_rel = OBJ_HEIGHT / IMG_HEIGHT\n",
    "            label_rows.append((labels[j], x_rel, y_rel, w_rel, h_rel))\n",
    "    save_example(f'{i+1:0{int(len(str(NUM_EXAMPLES)))}}', image, label_rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
